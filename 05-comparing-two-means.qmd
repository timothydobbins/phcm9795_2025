# Comparing the means of two groups

## Learning objectives {.unnumbered}

By the end of this module you will be able to:

-   Decide whether to use an independent samples t-test or a paired t-test to compare two the means of two groups;
-   Conduct and interpret the results from an independent samples t-test;
-   Describe the assumptions of an independent samples t-test;
-   Conduct and interpret the results from a paired t-test;
-   Describe the assumptions of a paired t-test;
-   Conduct an independent samples t-test and a paired t-test using software;
-   Report results and provide a concise summary of the findings of statistical analyses.

## Optional readings {.unnumbered}

@kirkwood_sterne01; Sections 7.1 to 7.5. [\[UNSW Library Link\]](http://er1.library.unsw.edu.au/er/cgi-bin/eraccess.cgi?url=https://ebookcentral.proquest.com/lib/unsw/detail.action?docID=624728)

@bland15; Section 10.3. [\[UNSW Library Link\]](http://er1.library.unsw.edu.au/er/cgi-bin/eraccess.cgi?url=https://ebookcentral.proquest.com/lib/unsw/detail.action?docID=5891730)

## Introduction

In Module 4, a one-sample t-test was used for comparing a single mean to a hypothesised value. In health research, we often want to compare the means between two groups. For example, in an observational study, we may want to compare cholesterol levels in people who exercise regularly to the levels in people who do not exercise regularly. In a clinical trial, we may want to compare cholesterol levels in people who have been randomised to a dietary modification or to usual care. In this module, we show how to compare the means of two groups where the analysis variable is normally distributed.

From the decision tree presented in the Appendix, we can see that if we have a continuous outcome measure and two categorical groups that are not related, i.e. a binary exposure measurement, the test for such data is an independent samples t-test. The test is also sometimes called a 2-sample t-test.

In research, data are often 'paired' or 'matched', that is the two data points are related to one another. This occurs when measurements are taken:

-   From each participant on two occasions, e.g. at baseline and follow-up in an experimental study or in a longitudinal cohort study;
-   From related people, e.g. a mother and daughter or a child and their sibling;
-   From related sites in the same person, e.g. from both limbs, eyes or kidneys;
-   From matched participants e.g. in a matched case-control study;
-   In cross-over clinical trials where the patient receives both drugs, often in random order.

An independent samples t-test cannot be used for analysing paired or matched data because the assumption that the two groups are independent is violated. Treating paired or matched measurements as independent samples would artificially inflate the sample size and lead to inaccurate P values. When the data are related in a paired or matched way and the outcome is continuous, a paired t-test is the appropriate statistic to use if the data are normally distributed.

## Independent samples t-test

An independent samples t-test is a parametric test that is used to assess whether the mean values of two groups are different from one another. Thus, the test is used to assess whether two mean values are similar enough to have come from the same population or whether the difference between them is so large that the two groups can be considered to have come from separate populations with different characteristics.

The null hypothesis is that the mean values of the two groups are not different, that is:

H~0~: ($\mu_1 - \mu_2$) = 0

Rejecting the null hypothesis using an independent samples t-test indicates that the difference between the means of the two groups is large in relation to the variability in the samples and is unlikely to be due to chance or to sampling variation.

### Assumptions for an independent samples t-test

The assumptions that must be met before an independent samples t-test can be used are:

-   The two groups are independent
-   The measurements are independent
-   The analysis variable must be continuous and must be normally distributed in each group

The first two assumptions are determined by the study design. The two samples must be independent, i.e. if a person is in one group then they cannot be included in the other group, and the measurements within a sample must be independent, i.e. each person must be included in their group once only.

The third assumption of normality is important although t-tests are robust to some degree of non-normality as long as there are no influential outliers and, more importantly, if the sample size is large. We examined how to assess normality in Module 2. If the data are not normally distributed, it may be possible to transform them using a mathematical function such as a logarithmic transformation. If not, then we may need to use non-parametric tests. This is examined in Module 9.

Traditionally, the variance of the analysis variable in each group was assumed to be equal. However, this assumption can be relaxed by using Welch's variation of the t-test. It has been recommended that this unequal-variances t-test be used in most, if not all situations [@west21; @delacre_etal17; @ruxton06].

### Worked Example 5.1

In an observational study of a random sample of 100 full term babies from the community, birth weight and gender were measured. There were 44 male babies and 56 female babies in the sample. The research question asked whether there was a difference in birth weights between boys and girls. The two groups are independent of each other and therefore an independent samples t-test can be used to test the null hypothesis that there is no difference in weight between the genders.

Exploratory data analysis of the variable of interest in each group should always be obtained before a t-test is undertaken to ensure that the assumptions are met. In particular, the distribution of the analysis variable should be examined for each group, as shown in @fig-mod05-bwt-gender. The `mod05_birthweight.rds` dataset is available on Moodle.

```{r fig-mod05-bwt-gender, echo=FALSE, out.width = "50%", fig.cap="Distribution of birth weight by gender"}
knitr::include_graphics(here::here("img", "mod05", "mod05-bwt-gender.png"))
```

The plots show that the data are approximately normally distributed: the density curves are relatively bell shaped and symmetric, and there are no outliers.

We can also describe the data using summary statistics:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#| label: tbl-5-1
#| tbl-cap: "Summary of birthweight by gender"

library(flextable)
library(gtsummary)

ex5_1 <- readRDS("data/examples/mod05_birthweight.rds")

tbl_summary(ex5_1, by=gender,
            type = all_continuous() ~ "continuous2",
            statistic = all_continuous() ~ c("{N_nonmiss}",
                                             "{mean} ({sd})",
                                     "{median} ({p25}, {p75})", 
                                     "{min} to {max}")) |>
  modify_header(all_stat_cols() ~ "**{level}**") |>
  add_stat_label(label = birthweight ~ c("Number", "Mean (SD)", "Median (Q1, Q3)", "Range")) |> 
  as_flex_table()

```

The table shows that girls have a mean weight of 3.59 kg (SD 0.36) and boys have a mean weight of 3.42 kg (SD 0.35) with females being heavier than males. The variabilities of birth weight (i.e. the standard deviation) are similar between the two groups.

### Conducting and interpreting an independent samples t-test

An independent samples t-test provides us with a t statistic from which we can compute a P value. The computation of the t statistic is as follows:

$$t = \frac{{\overline{x}}_{1} - {\overline{x}}_{2}}{SE({\overline{x}}_{1} - {\overline{x}}_{2})}$$

with the standard error and degrees of freedom calculated from software. Note that by using Welch's t-test, the degrees of freedom will usually not be a whole number, and will appear with decimals.

Looking at the formula for the t-statistic, we can see that the $t$ is an estimate of how different the mean values are compared to the variability of the difference in means. So $t$ will become larger as the difference in means increases with respect to the variability.

Statistical software will calculate both the t and P values. If the t-value is large, the P value will be small, providing evidence against the null hypothesis of no difference between the groups.

@tbl-ind-t summarises the results of an independent samples t-test using `mod05_birthweight.dta` or `mod05_birthweight.rds`. The process of conducting the t-test is summarised for jamovi and R in the following sections.

```{r, echo=FALSE}
#| label: tbl-ind-t
#| tbl-cap: "Birthweight (kg) by sex"

df <- tibble::tribble(
                ~Sex,  ~n,   ~`Mean (SE)`, ~`95% Confidence Interval`,
            "Female",  56, "3.59 (0.049)",             "3.49 to 3.68",
              "Male",  44, "3.42 (0.053)",             "3.31 to 3.53",
        "Difference",  NA, "0.17 (0.072)",             "0.02 to 0.31"
        )

flextable(df, cwidth=c(1, 0.5, 1.5, 1.5))
```

Here we see that girls are heavier than boys, and the mean difference in weights between the genders is 0.17 kg (95% CI 0.02, 0.31). We are 95% confident that the true mean difference of weight between girls and boys lies between 0.02 and 0.31 kg. Note that this interval does not contain the null value of 0.

Here we are testing the null hypothesis of no difference in mean birthweights between females and males: a two-sided test. The t-value is calculated as 2.30 with 93.5 degrees of freedom, and yields a two-sided P value of 0.023, providing evidence of a difference in mean birthweight between sex.

## Paired t-tests

If the outcome of interest is the difference in the continuously outcome measurement between each pair of observations, a paired t-test is used. In effect, a paired t-test is used to assess whether the mean of the differences between the two related measurements is significantly different from zero. In this sense, a paired t-test is very closely aligned with a one sample t-test.

When using a paired t-test, the variation *between the pairs* of measurements is the most important statistic. The variation between the participants is of little interest.

For related measurements, the data for each pair of values must be entered on the same row of the spreadsheet. Thus, the number of rows in the data sheet is the number of pairs of observations. Thus, the effective sample size is the total number of pairs and not the total number of measurements.

### Assumptions for a paired t-test

The assumptions for a paired t-test are:

-   the outcome variable is continuous
-   the differences between the pair of the measurements are normally distributed

For a paired samples t-test, it is important to test whether the *differences* between the two measurements are normally distributed. If the assumptions for a paired t-test cannot be met, a non-parametric equivalent is a more appropriate test to use (Module 9).

### Computing a paired t-test

The null hypothesis for using a paired t-test is as follows:

H~0~: Mean (Measurement1 -- Measurement2) = 0

To compute a t-value, the size of the mean difference between the two measurements is compared to the standard error of the paired differences, i.e.

$$t = \frac{\overline{d}}{SE(\overline{d})}$$

with *n*--1 degrees of freedom, where *n* is the number of pairs.

Because the standard error becomes smaller as the sample size becomes larger, the t-value increases as the sample size increases for the same mean difference.

### Worked Example 5.2

A total of 107 people were recruited into a study to assess whether ankle blood pressure measured in two different sites would be the same. For each person, systolic blood pressure (SBP) was measured in two sites: dorsalis pedis and tibialis posterior.

The dataset mod05_ankle_bp.xls is available on Moodle. First, we need to compute the pairwise difference between SBP measured in the two sites. The distribution of the difference between SBP measured in dorsalis pedis and tibialis posterior is shown in @fig-mod05-sbpdiff. The differences approximate a normal distribution and therefore a paired t-test can be used.

```{r fig-mod05-sbpdiff, echo=FALSE, out.width = "50%", fig.cap="Distribution of differences in ankle SBP between two sites of 107 participants"}
knitr::include_graphics(here::here("img", "mod05", "mod05-sbpdiff.png"))
```

The paired t-test can be performed using statistical software, with a summary of the results presented in @tbl-paired-t. We can see that the mean SBP is very similar in the two sites.

```{r, echo=FALSE}
#| label: tbl-paired-t
#| tbl-cap: "Systolic blood pressure (mmHg) measured at two sites on the ankle"

df <- tibble::tribble(
                       ~Site,   ~n,   ~`Mean (SE)`, ~`95% Confidence Interval`,
            "Dorsalis pedis", 107L, "116.7 (3.46)",         "(109.9 to 123.6)",
        "Tibialis posterior", 107L, "118.0 (3.43)",         "(111.2 to 124.8)",
                "Difference", 107L,  "-1.3 (1.31)",            "(-3.9 to 1.3)"
        )

flextable(df, cwidth=c(1.5, 0.5, 1, 1.5))
```

The t-value is calculated as −0.96 with 106 degrees of freedom, providing a two-sided P-value of 0.34. Thus these data provide no evidence of a difference in systolic blood pressure between the two sites.

<!-- {{< pagebreak >}} -->

<!-- # Jamovi notes {.unnumbered} -->

<!-- {{< include 05.1-comparing-two-means-jamovi.qmd >}} -->

<!-- {{< pagebreak >}} -->

<!-- # R notes {.unnumbered} -->

<!-- {{< include 05.2-comparing-two-means-R.qmd >}} -->

<!-- {{< pagebreak >}} -->

<!-- # Activities {.unnumbered} -->

<!-- {{< include 05.3-comparing-two-means-activities.qmd >}} -->
