<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Precision, standard errors and confidence intervals – PHCM9795: Foundations of Biostatistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-hypothesis-testing.html" rel="next">
<link href="./02-probability.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37e38b627515668d8a78bbca23c297a0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-9a71a2450f5674972ff858c43d8deec0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background: #ffdc00;
      }
</style>
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03-precision.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Precision, standard errors and confidence intervals</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Precision, standard errors and confidence intervals</span></h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">PHCM9795: Foundations of Biostatistics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Summarising and presenting data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and probability distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-precision.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Precision, standard errors and confidence intervals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">An introduction to hypothesis testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-comparing-two-means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Comparing the means of two groups</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Summary statistics for binary data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-testing-proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Hypothesis testing for categorical data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-correlation-and-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Correlation and simple linear regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-non-parametrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Analysing non-normal data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-sample-size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">An introduction to sample size estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning objectives</a></li>
  <li><a href="#optional-readings" id="toc-optional-readings" class="nav-link" data-scroll-target="#optional-readings">Optional readings</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">3.1</span> Introduction</a></li>
  <li><a href="#probability-for-continuous-variables" id="toc-probability-for-continuous-variables" class="nav-link" data-scroll-target="#probability-for-continuous-variables"><span class="header-section-number">3.2</span> Probability for continuous variables</a></li>
  <li><a href="#normal-distribution" id="toc-normal-distribution" class="nav-link" data-scroll-target="#normal-distribution"><span class="header-section-number">3.3</span> Normal distribution</a></li>
  <li><a href="#the-standard-normal-distribution" id="toc-the-standard-normal-distribution" class="nav-link" data-scroll-target="#the-standard-normal-distribution"><span class="header-section-number">3.4</span> The Standard Normal distribution</a></li>
  <li><a href="#assessing-normality" id="toc-assessing-normality" class="nav-link" data-scroll-target="#assessing-normality"><span class="header-section-number">3.5</span> Assessing Normality</a></li>
  <li><a href="#non-normally-distributed-measurements" id="toc-non-normally-distributed-measurements" class="nav-link" data-scroll-target="#non-normally-distributed-measurements"><span class="header-section-number">3.6</span> Non-Normally distributed measurements</a></li>
  <li><a href="#parametric-and-non-parametric-statistical-methods" id="toc-parametric-and-non-parametric-statistical-methods" class="nav-link" data-scroll-target="#parametric-and-non-parametric-statistical-methods"><span class="header-section-number">3.7</span> Parametric and non-parametric statistical methods</a></li>
  <li><a href="#other-types-of-probability-distributions" id="toc-other-types-of-probability-distributions" class="nav-link" data-scroll-target="#other-types-of-probability-distributions"><span class="header-section-number">3.8</span> Other types of probability distributions</a></li>
  <li><a href="#sampling-methods" id="toc-sampling-methods" class="nav-link" data-scroll-target="#sampling-methods"><span class="header-section-number">3.9</span> Sampling methods</a></li>
  <li><a href="#standard-error-and-precision" id="toc-standard-error-and-precision" class="nav-link" data-scroll-target="#standard-error-and-precision"><span class="header-section-number">3.10</span> Standard error and precision</a>
  <ul class="collapse">
  <li><a href="#sec-semean" id="toc-sec-semean" class="nav-link" data-scroll-target="#sec-semean"><span class="header-section-number">3.10.1</span> The standard error of the mean</a></li>
  </ul></li>
  <li><a href="#central-limit-theorem" id="toc-central-limit-theorem" class="nav-link" data-scroll-target="#central-limit-theorem"><span class="header-section-number">3.11</span> Central limit theorem</a>
  <ul class="collapse">
  <li><a href="#when-the-population-distribution-is-unknown" id="toc-when-the-population-distribution-is-unknown" class="nav-link" data-scroll-target="#when-the-population-distribution-is-unknown"><span class="header-section-number">3.11.1</span> When the population distribution is unknown:</a></li>
  <li><a href="#when-the-population-is-assumed-to-be-normal" id="toc-when-the-population-is-assumed-to-be-normal" class="nav-link" data-scroll-target="#when-the-population-is-assumed-to-be-normal"><span class="header-section-number">3.11.2</span> When the population is assumed to be normal:</a></li>
  </ul></li>
  <li><a href="#confidence-interval-of-the-mean" id="toc-confidence-interval-of-the-mean" class="nav-link" data-scroll-target="#confidence-interval-of-the-mean"><span class="header-section-number">3.12</span> 95% confidence interval of the mean</a>
  <ul class="collapse">
  <li><a href="#the-t-distribution-and-when-should-i-use-it" id="toc-the-t-distribution-and-when-should-i-use-it" class="nav-link" data-scroll-target="#the-t-distribution-and-when-should-i-use-it"><span class="header-section-number">3.12.1</span> The t-distribution and when should I use it?</a></li>
  <li><a href="#worked-example-3.1-95-ci-of-a-mean-using-individual-data" id="toc-worked-example-3.1-95-ci-of-a-mean-using-individual-data" class="nav-link" data-scroll-target="#worked-example-3.1-95-ci-of-a-mean-using-individual-data"><span class="header-section-number">3.12.2</span> Worked Example 3.1: 95% CI of a mean using individual data</a></li>
  <li><a href="#worked-example-3.2-95-ci-of-a-mean-using-summarised-data" id="toc-worked-example-3.2-95-ci-of-a-mean-using-summarised-data" class="nav-link" data-scroll-target="#worked-example-3.2-95-ci-of-a-mean-using-summarised-data"><span class="header-section-number">3.12.3</span> Worked Example 3.2: 95% CI of a mean using summarised data</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="learning-objectives" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="learning-objectives">Learning objectives</h2>
<p>By the end of this module you will be able to:</p>
<ul>
<li>Explain the purpose of sampling, different sampling methods and their implications for data analysis;</li>
<li>Distinguish between standard deviation of a sample and standard error of a mean;</li>
<li>Recognise the importance of the central limit theorem;</li>
<li>Calculate the standard error of a mean;</li>
<li>Calculate and interpret confidence intervals for a mean;</li>
<li>Be familiar with the t-distribution and when to use it.</li>
</ul>
</section>
<section id="optional-readings" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="optional-readings">Optional readings</h2>
<p><span class="citation" data-cites="kirkwood_sterne01">Kirkwood and Sterne (<a href="references.html#ref-kirkwood_sterne01" role="doc-biblioref">2001</a>)</span>; Chapters 4 and 6. <a href="http://er1.library.unsw.edu.au/er/cgi-bin/eraccess.cgi?url=https://ebookcentral.proquest.com/lib/unsw/detail.action?docID=624728">[UNSW Library Link]</a></p>
<p><span class="citation" data-cites="bland15">Bland (<a href="references.html#ref-bland15" role="doc-biblioref">2015</a>)</span>; Sections 3.3 and 3.4, 8.1 to 8.3. <a href="http://er1.library.unsw.edu.au/er/cgi-bin/eraccess.cgi?url=https://ebookcentral.proquest.com/lib/unsw/detail.action?docID=5891730">[UNSW Library Link]</a></p>
</section>
<section id="introduction" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">3.1</span> Introduction</h2>
<p>To describe the characteristics of a population we can gather data about the entire population (as is undertaken in a national census) or we can gather data from a sample of the population. When undertaking a research study, taking a sample from a population is far more cost-effective and less time consuming than collecting information from the entire population. When a sample of a population is selected, summary statistics that describe the sample are used to make inferences about the total population from which the sample was drawn. These are referred to as inferential statistics.</p>
<p>However, for the inferences about the population to be valid, a random sample of the population must be obtained. The goal of using random sampling methods is to obtain a sample that is representative of the target population. In other words, apart from random error, the information derived from the sample is expected to be much the same as the information collected from a complete population census as long as the sample is large enough.</p>
</section>
<section id="probability-for-continuous-variables" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="probability-for-continuous-variables"><span class="header-section-number">3.2</span> Probability for continuous variables</h2>
<p>Calculating the probability for a discrete random variable is relatively straightforward, as there are only a finite number of possible events. However, there are an infinite number of possible values for a continuous variable, and we calculate the probability that the continuous variable lies in a range of values.</p>
</section>
<section id="normal-distribution" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="normal-distribution"><span class="header-section-number">3.3</span> Normal distribution</h2>
<p>The frequency plot for many biological and clinical measurements (for example blood pressure and height) follow a bell shape where the curve is symmetrical about the mean value and has tails at either end. <a href="#fig-2-1" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and <a href="#fig-2-2" class="quarto-xref">Figure&nbsp;<span>3.2</span></a> <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> demonstrate this type of distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/dbp.png" class="img-fluid figure-img" style="width:66.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Distribution of diastolic blood pressure, 2017–18 Australian Bureau of Statistics National Health Survey
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/heights.png" class="img-fluid figure-img" style="width:66.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2: Distribution of male and female heights
</figcaption>
</figure>
</div>
</div>
</div>
<p>The Normal distribution, also called the Gaussian distribution (named after Johann Carl Friedrich Gauss, 1777–1855), has been shown to fit the frequency distribution of many naturally occurring variables. It is characterised by its bell-shaped, symmetric curve and its tails that approach zero on either side.</p>
<p>There are two reasons for the importance of the Normal distribution in biostatistics (Kirkwood and Sterne, 2003). The first is that many variables can be modelled reasonably well using the Normal distribution. Even if the observed data were not Normally distributed, it can often be made reasonably Normal after applying some transformation of the data. The second (and possible most important) reason, is based on the central limit theorem and will be discussed in Module 3.</p>
<p>The Normal distribution is characterised by two parameters: the mean (<span class="math inline">\(\mu\)</span>) and the standard deviation (<span class="math inline">\(\sigma\)</span>). The mean defines where the middle of the Normal distribution is located, and the standard deviation defines how wide the tails of the distribution are.</p>
<p>For a Normal distribution, about 68% of the observations lie between <span class="math inline">\(- \sigma\)</span> and <span class="math inline">\(\sigma\)</span> of the mean; 95% of the observations lie between <span class="math inline">\(−1.96 \times \sigma\)</span> and <span class="math inline">\(1.96 \times \sigma\)</span> from the mean; and almost all the observations (99.7%) lie between <span class="math inline">\(-3 \times \sigma\)</span> and <span class="math inline">\(3 \times \sigma\)</span> (<a href="#fig-2-3" class="quarto-xref">Figure&nbsp;<span>3.3</span></a>). Also note that the mean is the same as the median, as the curve is symmetric about its mean.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/normal-curve.png" class="img-fluid figure-img" style="width:66.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3: Characteristics of a Normal distribution
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="the-standard-normal-distribution" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="the-standard-normal-distribution"><span class="header-section-number">3.4</span> The Standard Normal distribution</h2>
<p>As each Normal distribution is defined by its mean and standard deviation, there are an infinite number of possible Normal distributions. However, every Normal distribution can be transformed to what we call the Standard Normal distribution, which has a mean of zero (<span class="math inline">\(\mu = 0\)</span>) and a standard deviation of one (<span class="math inline">\(\sigma = 1\)</span>). The Standard Normal distribution is so important that it has been assigned its own symbol: Z.</p>
<p>Every observation from a Normal distribution <span class="math inline">\(X\)</span> with a mean <span class="math inline">\(\mu\)</span> and a standard deviation <span class="math inline">\(\sigma\)</span> can be transformed to a z-score (also called a Standard Normal deviate) by the formula:</p>
<p><span class="math display">\[ z = \frac{x - \mu}{\sigma} \]</span></p>
<p>The z-score is simply how far an observation lies from the population mean value, scaled by the population standard deviation.</p>
<p>We can use z-scores to estimate probabilities, as shown in Worked Example 2.2.</p>
<section id="worked-example" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="worked-example">Worked Example</h4>
<p>This example extends the example of diastolic blood pressure shown in <a href="#fig-2-1" class="quarto-xref">Figure&nbsp;<span>3.1</span></a>. Assume that the mean diastolic blood pressure for men is 77.9 mmHg, with a standard deviation of 11. What is the probability that a man selected at random will have high blood pressure (i.e.&nbsp;diastolic blood pressure ≥ 90)?</p>
<p>To estimate the probability that diastolic blood pressure ≥ 90 (i.e.&nbsp;the upper tail probability), we first need to calculate the z-score that corresponds to 90 mmHg.</p>
<p>Using the z-score formula, with x=90, <span class="math inline">\(\mu\)</span>=77.9 and <span class="math inline">\(\sigma\)</span>=11:</p>
<p><span class="math display">\[ z = \frac{90 - 77.9}{11} = 1.1 \]</span> Thus, a blood pressure of 90 mmHg corresponds to a z-score of 1.1, or a value 1.1 <span class="math inline">\(\times \sigma\)</span> above the mean weight of the population.</p>
<p><a href="#fig-2-5" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> shows the probability of a diastolic blood pressure of 90 mmHg or more in the population for a z-score of greater than 1.1 on a Standard Normal distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/z-dist-shaded.png" class="img-fluid figure-img" style="width:66.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: Area under the Standard Normal curve (as probability) for Z &gt; 1.1
</figcaption>
</figure>
</div>
</div>
</div>
<p>Using software, we find the probability that a person has a diastolic blood pressure of 90 mmHg or more as P(Z ≥ 1.1) = 0.136 (see <span class="quarto-unresolved-ref">?sec-normal-stata</span> and <span class="quarto-unresolved-ref">?sec-normal-r</span> for details).</p>
<p>Apart from calculating probabilities, z-scores are most useful for comparing measurements taken from a sample to a known population distribution. It allows measurements to be compared to one another despite being on different scales or having different predicted values.</p>
<p>For example, if we take a sample of children and measure their weights, it is useful to describe those weights as z-scores from the population weight distribution for each age and gender. Such distributions from large population samples are widely available. This allows us to describe a child’s weight in terms of how much it is above or below the population average. For example, if mean weights were compared, children aged 5 years would be on average heavier than the children aged 3 years simply because they are older and therefore larger. To make a valid comparison, we could use the Z-scores to say that children aged 3 years tend to be more overweight than children aged 5 years because they have a higher mean z-score for weight.</p>
</section>
</section>
<section id="assessing-normality" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="assessing-normality"><span class="header-section-number">3.5</span> Assessing Normality</h2>
<p>There are several ways to assess whether a continuous variable is Normally distributed. With a large sample, simply plotting a histogram is one of the best ways to assess whether a variable is Normally distributed. For smaller samples, examining a histogram can be less clear, particularly for histograms with only a small number of bins. However, if a histogram looks bell-shaped and approximately symmetrical, assuming Normality would be reasonable.</p>
<p>It may be useful to examine a boxplot of a variable in conjunction with a histogram. However a boxplot in isolation is not as useful as a histogram, as a boxplot only indicates whether a variable is distributed symmetrically (indicated by equal “whiskers”). A boxplot cannot give an indication of whether the distribution is bell-shaped, or flat.</p>
<blockquote class="blockquote">
<p>For your information: There are formal tests in Stata and R that test for Normality. These tests are beyond the scope of this course and are not recommended.</p>
</blockquote>
<p>The histogram for our 30 weights is approximately bell-shaped and roughly symmetrical. The mean and median (50th percentile) values are similar, as would be expected for a Normal distribution. Thus, it would be reasonable to assume that the data are Normally distributed.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/weights-hist-boxplot.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: Histogram and boxplot of weight of 30 students attending a gym
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="non-normally-distributed-measurements" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="non-normally-distributed-measurements"><span class="header-section-number">3.6</span> Non-Normally distributed measurements</h2>
<p>In the above example, diastolic blood pressure was Normally distributed with an approximately bell-shaped frequency histogram. However, not all measurements are Normally distributed, and the symmetry of the bell shape may be distorted by the presence of some very small or very large values. Non-Normal distributions such as this are called skewed distributions.</p>
<p>When there are some very large values, the distribution is said to be positively skewed.This often occurs when measuring variables related to time, such as days of hospital stay, where most patients have short stays (say 1 - 5 days) but a few patients with serious medical conditions have very long lengths of hospital stay (say 20 - 100 days).</p>
<p>In practice, most parametric summary statistics are quite robust to minor deviations from Normality and non-parametric statistical methods are only required when the sample size is small and/or the data are obviously skewed with some influential outliers.</p>
<p>When the data are markedly skewed, histograms and boxplots can look very different. For example, data of length of hospital stay in a sample of children are shown as a histogram and as a box plot in <a href="#fig-2-7" class="quarto-xref">Figure&nbsp;<span>3.6</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2-7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod02/los-hist-boxplot.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Histogram and boxplot of length of stay
</figcaption>
</figure>
</div>
</div>
</div>
<p>In the histogram of <a href="#fig-2-7" class="quarto-xref">Figure&nbsp;<span>3.6</span></a>, there is a tail of values to the right, so we would conclude that the distribution is skewed to the right. In the boxplot, the whiskers appear to be fairly symmetric, but there are some unusual values (denoted by dots) above the box and its whiskers. Stata defines these unusual values as being more than 1.5 times the IQR from the edge of the box.</p>
<p>The presence of unusual values may be an indication that the data are not Normally distributed. Both the histogram and the box plot show that the distribution has a marked tail towards high values and that non-parametric statistics should be used to generate summary statistics and analyse the data.</p>
<p>Note that Stata has defined points as being unusual, or outliers. Outliers can be problematic and the decision to include them or omit them from further analyses can be difficult. After detecting any outliers or extreme values, you should not automatically exclude them from the analysis, particularly if the sample was selected randomly from a population. First, it is important to check the original data collection form or questionnaire to rule out the possibility of a data entry error. If the outlier is not a data entry error, it is then important to decide whether the observation is biologically plausible and, if it is, it should be included in the analysis.</p>
</section>
<section id="parametric-and-non-parametric-statistical-methods" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="parametric-and-non-parametric-statistical-methods"><span class="header-section-number">3.7</span> Parametric and non-parametric statistical methods</h2>
<p>Many statistical methods are based on assumptions about the distribution of the variable – these methods are known as parametric statistical methods. Many methods of statistical inferences based on theoretical sampling properties that are derived from a Normal distribution with the characteristics described above. Thus, it is important that measurements approximate to a Normal distribution before these parametric methods are used. The methods are called ‘parametric’ because they are based on the parameters – the mean and standard deviation - that underlie a Normal distribution. Statistics which do not assume a particular distribution are called distribution-free statistics, or ‘non-parametric statistics’.</p>
<p>In this course, you will learn about both parametric and non-parametric statistical methods. Parametric summary statistical methods include those based on the mean, standard deviation and range (Module 1), and standard error and 95% confidence interval (Module 3). Parametric statistical tests also include t-tests which will be covered in Modules 4 and 5, and correlation and regression described in Module 8.</p>
<p>Non-parametric summary statistical methods are often based on ranks, and may use such statistics as the median, mode and inter-quartile range (Module 1). Non-parametric statistical tests that use ranking are described in Module 9.</p>
</section>
<section id="other-types-of-probability-distributions" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="other-types-of-probability-distributions"><span class="header-section-number">3.8</span> Other types of probability distributions</h2>
<p>In this module we have considered a Normal probability distribution and how to use it to measure the precision of continuously distributed measurements. Data also follow other types of distributions which are briefly described below. In other modules in this course, we will be looking at a range of methods to analyse health data and will refer back to these different distributions.</p>
<p>Normal approximation of binomial: When the sample size becomes large, it becomes cumbersome to calculate the exact probability of an event using the binomial distribution. Conveniently, with large sample sizes, the binomial distribution approximates a Normal distribution. The mean and SD of a binomial distribution can be used to calculate the probability of the event as though it was from a Normal distribution.</p>
<p>Poisson distribution: is another distribution which is often used in health research for modelling count data. The Poisson distribution is followed when a number of events happen in a fixed time interval. This distribution is useful for describing data such as deaths in the population in a time period. For example, the number of deaths from breast cancer in one year in women over 50 years old will be an observation from a Poisson distribution. We can also use this to make comparisons of mortality rates between populations.</p>
<p>Many other probability distributions can be derived for functions which arise in statistical analyses but the chi-squared, t and F distributions are the three distributions that are most widely used. These have many applications, some of which are described in later modules.</p>
<p>The chi-squared distribution is a skewed distribution which allows us to determine the probability of a deviation between a count that we observe and a count that we expect for categorical data. One use of this is in conducting statistical tests for categorical data. See Module 7.</p>
<p>A t-distribution is used when the population standard deviation is not known. The t-distribution is appropriate for small samples (&lt;30) and its distribution is bell shaped similar to a Normal distribution but slightly flatter. The t-distribution is useful for comparing mean values. See Module 4 and Module 5.</p>
</section>
<section id="sampling-methods" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="sampling-methods"><span class="header-section-number">3.9</span> Sampling methods</h2>
<p>Methods have been designed to select participants from a population such that each person in the target population has an equal probability of being chosen. Methods that use this approach are called random sampling methods. Examples include simple random sampling and stratified random sampling.</p>
<p>In simple random sampling, every person in the population from which the sample is drawn has the same random chance of being selected into the sample. To implement this method, every person in the population is allocated an ID number and then a random sample of the ID numbers is selected. Software packages can be used to generate a list of random numbers to select the random sample.</p>
<p>In stratified sampling, the population is divided into distinct non-overlapping subgroups (strata) according to an important characteristic (e.g.&nbsp;age or sex) and then a random sample is selected from each of the strata. This method is used to ensure that sufficient numbers of people are sampled from each stratum and therefore each subgroup of interest is adequately represented in the sample.</p>
<p>The purpose of using random sampling is to minimise selection bias to ensure that the sample enrolled in a study is representative of the population being studied. This is important because the summary statistics that are obtained can then be regarded as valid in that they can be applied (generalised) back to the population.</p>
<p>A non-representative sample might occur when random sampling is used, simply by chance. However, non-random sampling methods, such as using a study population that does not represent the whole population, will often result in a non-representative sample being selected so that the summary statistics from the sample cannot be generalised back to the population from which the participants were drawn. The effects of non-random error are much more serious than the effects of random error. Concepts such as non-random error (i.e.&nbsp;systematic bias), selection bias, validity and generalisability are discussed in more detail in PHCM9796: Foundations of Epidemiology.</p>
</section>
<section id="standard-error-and-precision" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="standard-error-and-precision"><span class="header-section-number">3.10</span> Standard error and precision</h2>
<p>Module 1 introduced the mean, variance and standard deviation as measures of central tendency and spread for continuous measurements from a sample or a population. As described in Module 1, we rarely have data on the entire population but we <em>infer</em> information <em>about</em> the population from a <em>sample</em>. For example, we use the sample mean <span class="math inline">\(\bar x\)</span> as an <em>estimate</em> of the true population mean <span class="math inline">\(\mu\)</span>.</p>
<p>However, a sample taken from a population is usually a small proportion of the total population. If we were to take multiple samples of data and calculate the sample mean for each sample, we would not expect them to be identical. If our samples were very small, we would not be surprised if our estimated sample means were somewhat different from each other. However, if our samples were large, we would expect the sample means to be less variable, i.e.&nbsp;the estimated sample means would be more close to each other, and hopefully, to the true population mean.</p>
<section id="sec-semean" class="level3" data-number="3.10.1">
<h3 data-number="3.10.1" class="anchored" data-anchor-id="sec-semean"><span class="header-section-number">3.10.1</span> The standard error of the mean</h3>
<p>A point estimate is a single best guess of the true value in the population - taken from our sample of data. Different samples will provide slightly different point estimates. The standard error is a measure of variability of the point estimate.</p>
<p>In particular, the <em>standard error of the mean</em> measures the extent to which we expect the means from different samples to vary because of chance due to the sampling process. This statistic is directly proportional to the standard deviation of the variable, and inversely proportional to the size of the sample. The standard error of the mean for a continuously distributed measurement for which the SD is an accurate measure of spread is computed as follows:</p>
<p><span class="math display">\[ \text{SE}(\bar{x}) = \frac{\text{SD}}{\sqrt{n}} \]</span></p>
<p>Take for example, a set of weights of students attending a university gym in a particular hour. The thirty weights are given below:</p>
<div class="cell">
<div id="tbl-3-weights" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-3-weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.1: Weight of 30 gym attendees
</figcaption>
<div aria-describedby="tbl-3-weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-c2d27d56{}.cl-c2cf1238{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c2d063d6{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c2d070b0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c2d070ba{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c2d070bb{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-c2d27d56"><thead><tr style="overflow-wrap:break-word;"><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v1</span></p></th><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v2</span></p></th><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v3</span></p></th><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v4</span></p></th><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v5</span></p></th><th class="cl-c2d070b0"><p class="cl-c2d063d6"><span class="cl-c2cf1238">v6</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">65</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">67.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">65.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">80.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">72.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">67.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">62.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">67.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">72.5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">60</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">65.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">72.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">77.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">75.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">75.0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">75</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70.0</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">67.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">77.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">67.5</span></p></td><td class="cl-c2d070ba"><p class="cl-c2d063d6"><span class="cl-c2cf1238">62.5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">75</span></p></td><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">62.5</span></p></td><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70.0</span></p></td><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">75.0</span></p></td><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">72.5</span></p></td><td class="cl-c2d070bb"><p class="cl-c2d063d6"><span class="cl-c2cf1238">70.0</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
</div>
<p>We can calculate the mean (70.0kg) and the standard deviation (5.04kg). Hence, the standard error of the mean is estimated as:</p>
<p><span class="math display">\[ \text{SE}(\bar{x}) = \frac{5.04}{\sqrt{30}} = 0.92 \]</span> Because the calculation uses the sample size (n) (i.e.&nbsp;the number of study participants) in the denominator, the SE will become smaller when the sample size becomes larger. A smaller SE indicates that the estimated mean value is more precise.</p>
<p>The standard error is an important statistic that is related to sampling variation. When a random sample of a population is selected, it is likely to differ in some characteristic compared with another random sample selected from the same population. Also, when a sample of a population is taken, the true population mean is an unknown value.</p>
<p>Just as the standard deviation measures the spread of the data around the population mean, the standard error of the mean measures the spread of the sample means. Note that we do not have different samples, only one. It is a theoretical concept which enables us to conduct various other statistical analyses.</p>
</section>
</section>
<section id="central-limit-theorem" class="level2" data-number="3.11">
<h2 data-number="3.11" class="anchored" data-anchor-id="central-limit-theorem"><span class="header-section-number">3.11</span> Central limit theorem</h2>
<p>Even though we now have an estimate of the mean and its standard error, we might like to know what the mean from a different random sample of the same size might be. To do this, we need to know how sample means are distributed. In determining the form of the probability distribution of the sample mean (<span class="math inline">\(\bar{x}\)</span>), we consider two cases:</p>
<section id="when-the-population-distribution-is-unknown" class="level3" data-number="3.11.1">
<h3 data-number="3.11.1" class="anchored" data-anchor-id="when-the-population-distribution-is-unknown"><span class="header-section-number">3.11.1</span> When the population distribution is unknown:</h3>
<p>The central limit theorem for this situation states:</p>
<blockquote class="blockquote">
<p>In selecting random samples of size <span class="math inline">\(n\)</span> from a population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, the sampling distribution of the sample mean <span class="math inline">\(\bar{x}\)</span> approaches a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\tfrac{\sigma}{\sqrt{n}}\)</span> as the sample size becomes large.</p>
</blockquote>
<p>The sample size n = 30 and above is a rule of thumb for the central limit theorem to be used. However, larger sample sizes may be needed if the distribution is highly skewed.</p>
</section>
<section id="when-the-population-is-assumed-to-be-normal" class="level3" data-number="3.11.2">
<h3 data-number="3.11.2" class="anchored" data-anchor-id="when-the-population-is-assumed-to-be-normal"><span class="header-section-number">3.11.2</span> When the population is assumed to be normal:</h3>
<blockquote class="blockquote">
<p>In this case the sampling distribution of <span class="math inline">\(\bar{x}\)</span> is normal for any sample size.</p>
</blockquote>
</section>
</section>
<section id="confidence-interval-of-the-mean" class="level2" data-number="3.12">
<h2 data-number="3.12" class="anchored" data-anchor-id="confidence-interval-of-the-mean"><span class="header-section-number">3.12</span> 95% confidence interval of the mean</h2>
<p>In Module 2, we showed that the characteristics of a Standard Normal Distribution are that 95% of the data lie within 1.96 standard deviations from the mean (<a href="#fig-2-2" class="quarto-xref">Figure&nbsp;<span>3.2</span></a>). Because the central limit theorem states that the sampling distribution of the mean is approximately Normal in large enough samples, we expect that 95% of the mean values would fall within 1.96 × SE units above and below the measured mean population value.</p>
<p>For example, if we repeated the study on weight 100 times using 100 different random samples from the population and calculated the mean weight for each of the 100 samples, approximately 95% of the values for the mean weight calculated for each of the 100 samples would fall within 1.96 × SE of the population mean weight.</p>
<p>This interpretation of the SE is translated into the concept of precision as a 95% confidence interval (CI). A 95% CI is a range of values within which we have 95% confidence that the true population mean lies. If an experiment was conducted a very large number of times, and a 95%CI was calculated for each experiment, 95% of the confidence intervals would contain the true population mean.</p>
<p>The calculation of the 95% CI for a mean is as follows:</p>
<p><span class="math display">\[  \bar{x} \pm 1.96 \times \text{SE}( \bar{x} ) \]</span> This is the generic formula for calculating 95% CI for any summary statistic. In general, the mean value can be replaced by the point estimate of a rate or a proportion and the same formula applies for computing 95% CIs, i.e.</p>
<p><span class="math display">\[ 95\% \text{ CI} = \text{point estimate} \pm 1.96 \times \text{SE}(\text{point estimate)} \]</span></p>
<p>The main difference in the methods used to calculate the 95% CI for different point estimates is the way the SE is calculated. The methods for calculating 95% CI around proportions and other ratio measures will be discussed in Module 6.</p>
<p>The use of 1.96 as a general critical value to compute the 95% CI is determined by sampling theory. For the confidence interval of the mean, the critical value (1.96) is based on normal distribution (true when the population SD is known). However, in practice, statistical packages will provide slightly different confidence intervals because they use a critical value obtained from the t-distribution. The t-distribution approaches a normal distribution when the sample size approaches infinity, and is close to a normal distribution when the sample size is ≥30.The critical values obtained from the t-distribution are always larger than the corresponding critical value from the normal distribution. The difference gets smaller as the sample size becomes larger. For example, when the sample size n=10, the critical value from the t-distribution is 2.26 (rather than 1.96); when n= 30, the value is 2.05; when n=100, the value is 1.98; and when n=1000, the critical value is 1.96.</p>
<p>The critical value multiplied by SE (for normal distribution, 1.96 × SE) is called the maximum likely error for 95% confidence.</p>
<section id="the-t-distribution-and-when-should-i-use-it" class="level3" data-number="3.12.1">
<h3 data-number="3.12.1" class="anchored" data-anchor-id="the-t-distribution-and-when-should-i-use-it"><span class="header-section-number">3.12.1</span> The t-distribution and when should I use it?</h3>
<p>The population standard deviation (<span class="math inline">\(\sigma\)</span>) is required for calculation of the standard error. Usually, <span class="math inline">\(\sigma\)</span> is not known and the sample standard deviation (<span class="math inline">\(s\)</span>) is used to estimate it. It is known, however, that the sample standard deviation of a normally distributed variable underestimates the true value of <span class="math inline">\(\sigma\)</span>, particularly when the sample size is small.</p>
<p>Someone by the pseudonym of Student came up with the Student’s t distribution with (<span class="math inline">\(n-1\)</span>) degrees of freedom to account for this underestimation. It looks very much like the standardised normal distribution, only that it has fatter tails (<a href="#fig-mod03-z-t-dist" class="quarto-xref">Figure&nbsp;<span>3.7</span></a>). As the degrees of freedom increase (i.e.&nbsp;as <span class="math inline">\(n\)</span> increases), the t-distribution gradually approaches the standard normal distribution. With a sufficiently large sample size, the Student’s t-distribution closely approximates the standardised normal distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mod03-z-t-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mod03-z-t-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/mod03/mod03-z-t-dist.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mod03-z-t-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.7: The normal (Z) and the student’s t-distribution with 2, 5 and 30 degrees of freedom
</figcaption>
</figure>
</div>
</div>
</div>
<p>If a variable <span class="math inline">\(X\)</span> is normally distributed and the population standard deviation <span class="math inline">\(\sigma\)</span> is known, using the normal distribution is appropriate. However, if <span class="math inline">\(\sigma\)</span> is not known then one should use the student t-distribution with (<span class="math inline">\(n – 1\)</span>) degrees of freedom.</p>
</section>
<section id="worked-example-3.1-95-ci-of-a-mean-using-individual-data" class="level3" data-number="3.12.2">
<h3 data-number="3.12.2" class="anchored" data-anchor-id="worked-example-3.1-95-ci-of-a-mean-using-individual-data"><span class="header-section-number">3.12.2</span> Worked Example 3.1: 95% CI of a mean using individual data</h3>
<p>The diastolic blood pressure of 733 female Pima indigenous Americans was measured, and a density plot showed that the data were approximately normally distributed. The mean diastolic blood pressure in the sample was 72.4 mmHg with a standard deviation of 12.38 mmHg. These data are saved as <code>mod03_blood_pressure.csv</code>.</p>
<p>Use Jamovi or R, we can calculate the mean, its Standard Error, and the 95% confidence interval:</p>
<div id="tbl-mean-ci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mean-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.2: Summary of blood pressure from female Pima indigenous Americans
</figcaption>
<div aria-describedby="tbl-mean-ci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>n</th>
<th>Mean</th>
<th>Standard deviation</th>
<th>Standard error of the mean</th>
<th>95% confidence interval of the mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>733</td>
<td>72.4</td>
<td>12.38</td>
<td>0.46</td>
<td>71.5 to 73.3</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>We can interpret this confidence interval as: we are 95% confident that the true mean of female Pima indigenous Americans lies between 71.5 and 73.3 mmHg.</p>
</section>
<section id="worked-example-3.2-95-ci-of-a-mean-using-summarised-data" class="level3" data-number="3.12.3">
<h3 data-number="3.12.3" class="anchored" data-anchor-id="worked-example-3.2-95-ci-of-a-mean-using-summarised-data"><span class="header-section-number">3.12.3</span> Worked Example 3.2: 95% CI of a mean using summarised data</h3>
<p>The publication of a study using a sample of 242 participants reported a sample mean systolic blood pressure of 128.4 mmHg and a sample standard deviation of 19.56 mmHg. Find the 95% confidence interval for the mean systolic blood pressure.</p>
<p>Using Jamovi or R, we obtain a 95% confidence interval from 125.9232 to 130.8768.</p>
<p>We are 95% confident that the true mean systolic blood pressure of the population from which the sample was drawn lies between 125.9 kg and 130.9 mmHg.</p>
<!--  -->
<!-- # Jamovi notes {.unnumbered} -->
<!-- {{< include 03.1-precision-jamovi.qmd >}} -->
<!--  -->
<!-- # R notes {.unnumbered} -->
<!-- {{< include 03.2-precision-R.qmd >}} -->
<!--  -->
<!-- # Activities {.unnumbered} -->
<!-- {{< include 03.3-precision-activities.qmd >}} -->


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bland15" class="csl-entry" role="listitem">
Bland, Martin. 2015. <em>An <span>Introduction</span> to <span>Medical Statistics</span></em>. 4th Edition. Oxford, New York: Oxford University Press.
</div>
<div id="ref-kirkwood_sterne01" class="csl-entry" role="listitem">
Kirkwood, Betty, and Jonathan Sterne. 2001. <em>Essentials of <span>Medical Statistics</span></em>. 2nd edition. Malden, Mass: Wiley-Blackwell.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Source: https://www.aihw.gov.au/reports/risk-factors/high-blood-pressure/contents/high-blood-pressure (accessed March 2021)<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Source: https://ourworldindata.org/human-height (accessed March 2021)<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-probability.html" class="pagination-link" aria-label="Probability and probability distributions">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability and probability distributions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-hypothesis-testing.html" class="pagination-link" aria-label="An introduction to hypothesis testing">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">An introduction to hypothesis testing</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>